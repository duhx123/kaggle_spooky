import pandas as pd
import numpy as np
import nltk
import re
import matplotlib.pyplot as plt
import seaborn as sns
# from wordcloud import WordCloud
import sys
import string
import operator
from nltk.corpus import stopwords
from sklearn.decomposition import TruncatedSVD
import gensim
from sklearn import metrics, model_selection, naive_bayes
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import CountVectorizer
import scipy.sparse
import xgboost as xgb
from sklearn import metrics, model_selection

reload(sys)
sys.setdefaultencoding('utf-8')

# reading source file
train = pd.read_csv('../data/train.csv')
test = pd.read_csv('../data/test.csv')
print(train.shape)  # (19579, 3)
print(test.shape)  # (8392, 2)

nrow_train = train.shape[0]
combined = pd.concat([train, test]).reset_index(drop=True)
print(combined.shape)  # (27971, 3)
# print(combined.head())
print(combined.author.value_counts())


def top_20_words(author):
    # Return lists of words
    common_words_df = (combined[combined.author == author].text
        .apply(lambda text: text.translate(None, string.punctuation)).str.lower().str.split(' '))
    # dictionary: key = words and values = word counts
    dict_of_word_count = {}
    for text in common_words_df:
        for word in text:
            dict_of_word_count[word] = dict_of_word_count.get(word, 0) + 1
    return sorted(dict_of_word_count.iteritems(), key=lambda (v, k): (k, v), reverse=True)[0:20]


sns.set(font_scale=1.25)


# print(top_20_words('EAP')[0])
def plot_top_20_words(author):
    plt.figure(figsize=(20, 12))
    topwords = top_20_words(author)
    words = zip(*topwords)[0]
    freq = zip(*topwords)[1]
    x_pos = np.arange(len(words))
    sns.barplot(x_pos, freq)
    plt.xticks(x_pos, words)
    plt.title('Top 20 words of: ' + author)
    plt.show()


# plot_top_20_words('EAP')


# wordcloud = WordCloud().generate(str(combined[combined.author=='EAP'].text.tolist()))

# plt.figure(figsize=(20, 15))
# plt.imshow(wordcloud, interpolation="bilinear")
# plt.axis("off")
# plt.show()


# add features using re
def clean_text(text):
    cleaned_text = text.translate(None, string.punctuation)
    return ' '.join([word.lower() for word in cleaned_text.split(' ')])


def feature_re():
    # Sentence Length
    combined['sent_length'] = combined.text.apply(lambda x: len(x))
    # Number of Words
    combined['no_of_words'] = combined.text.apply(lambda text: len(text.split(' ')))
    # Average Number of Capital Letters
    combined['avg_cap_letter'] = (
            combined.text.apply(lambda x: len(re.findall('[A-Z][A-Za-z]+', x))) / combined.no_of_words)
    # Average Word Length
    combined['avg_word_length'] = combined.sent_length / combined.no_of_words
    # Word Length Variance
    combined['word_len_var'] = combined.text.apply(lambda x: np.var([len(word) for word in x.split(' ')]))
    # Average Word Length
    combined['word_len_mean'] = combined.text.apply(lambda text: np.mean([len(word) for word in text.split(' ')]))
    # Number of stopwords
    combined['no_stopwords'] = combined.text.apply(
        lambda x: len([s for s in x.lower().split(' ') if s in stopwords.words('english')]))
    # Number of punctuations
    combined['no_punc'] = combined.text.apply(
        lambda x: len([s for s in x if s in string.punctuation]))
    # Reading Ease
    # combined['reading_ease'] = combined.text.apply(lambda text: textstat.flesch_reading_ease(text))
    # Number of Unique Words
    cleaned_text = combined.text.apply(clean_text)
    combined['unique_words'] = cleaned_text.apply(lambda text: len(set(text.split(' ')))) / combined.no_of_words


feature_re()


# nltk.download("stopwords")
def clean_text2(text):
    # Remove punctuations from the text
    cleaned_text = text.translate(None, string.punctuation)
    # Converting all upper cases to lower cases
    cleaned_text = [word.lower() for word in cleaned_text.split(' ')]
    # Removing stopwords
    return ' '.join([word for word in cleaned_text if word not in stopwords.words('english')])


combined['cleaned_text'] = combined.text.apply(clean_text2)


# Adding the number of punctuation marks as features in our combined dataframe
def feature_punc():
    combined['fullstops'] = combined.text.apply(lambda text: len(re.findall('\.', text))) / combined.no_of_words
    combined['commas'] = combined.text.apply(lambda text: len(re.findall('\,', text))) / combined.no_of_words
    combined['single_inv_commas'] = combined.text.apply(lambda text: len(re.findall("\'", text))) / combined.no_of_words
    combined['double_inv_commas'] = combined.text.apply(lambda text: len(re.findall('\"', text))) / combined.no_of_words
    combined['semicolons'] = combined.text.apply(lambda text: len(re.findall('\;', text))) / combined.no_of_words
    combined['colons'] = combined.text.apply(lambda text: len(re.findall('\:', text))) / combined.no_of_words


del combined['sent_length']
feature_punc()
# print(combined.head)

# plt.figure(figsize=(20,12))
# sns.heatmap(combined.corr(), annot=True)
# plt.show()

# nltk.download()
# Conduct POS Tagging (takes a bit of time to run this code)
pos_tags = (combined.text.apply(lambda text: nltk.pos_tag(nltk.word_tokenize(text.decode('utf-8')))))


def pos_tag_count(list_of_postag):
    # Return dictionary of dataframes with postags as keys and counts as values
    dict_of_postags = {}
    for tag in list_of_postag:
        dict_of_postags[tag[1]] = dict_of_postags.get(tag[1], 0) + 1
    return dict_of_postags


# print(pos_tags.apply(pos_tag_count)) #0        {u'MD': 1, u'PRP$': 2, u'VBG': 2, u'JJ': 2, u'...}

postags_df = pd.DataFrame(pos_tags.apply(pos_tag_count).to_dict()).T
# print(postags_df.head)
# Removing punctuation counts
pos_tag_col = [col for col in postags_df.columns if re.findall('[A-Z]+', col)]

# Fill NA values with 0, as there were no occurrences
postags_df_ = postags_df[pos_tag_col].fillna(0)

# del postags_df_['EAP']
# del postags_df_['HPL']
# del postags_df_['MWS']

combined = pd.merge(combined, postags_df_, left_index=True, right_index=True)


# print(combined.head)


def train_test_split_df():
    return combined.iloc[:nrow_train], combined.iloc[nrow_train:]


X_train, X_test = train_test_split_df()

# Use TfidfVectorizor to remove english stopwords and tokens that don't appear in at least 2 documents
# Only focus on unigrams, bigrams and trigrams
min_df = 2
ngram_range = (1, 3)


def vectorize_tfidf(min_df, ngram_range):
    vect = TfidfVectorizer(min_df=min_df,
                           ngram_range=ngram_range,
                           stop_words='english')
    # Fit on the whole dataframe
    full_tfidf = vect.fit_transform(combined.text)
    # Conduct transformation on the training and test dataframe
    train_tfidf = vect.transform(X_train.text)
    test_tfidf = vect.transform(X_test.text)
    return full_tfidf, train_tfidf, test_tfidf


full_tfidf, train_tfidf, test_tfidf = vectorize_tfidf(min_df=min_df, ngram_range=ngram_range)


# print(train_tfidf[0]) # (0, 37498)	0.187088433314955    (0, 36351)  	0.25276420165656954


def dim_reduce_tfidf(n_comp, full_tfidf):
    # Conduct dimensionality reduction on the dataframe using Truncated SVD
    svd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')
    svd_obj.fit(full_tfidf)
    train_svd = pd.DataFrame(svd_obj.transform(train_tfidf))
    test_svd = pd.DataFrame(svd_obj.transform(test_tfidf))
    train_svd.columns = ['svd_word_' + str(i) for i in range(n_comp)]
    test_svd.columns = ['svd_word_' + str(i) for i in range(n_comp)]
    return pd.concat([train_svd, test_svd])


# We settle on 25 components
tfidf_sparse = dim_reduce_tfidf(n_comp=25, full_tfidf=full_tfidf)
print(tfidf_sparse.head(5))

# Use CountVectorizor to remove stop_words, remove tokens that don't appear in at least 1 document,
# Focus only on unigrams, bigrams and trigrams
min_df = 1
ngram_range = (1, 3)


def vectorize_count(min_df, ngram_range):
    vect = CountVectorizer(min_df=min_df,
                           ngram_range=ngram_range,
                           stop_words='english')
    full_count = vect.fit_transform(combined.text)
    train_count = vect.transform(X_train.text)
    test_count = vect.transform(X_test.text)
    return full_count, train_count, test_count


full_count, train_count, test_count = vectorize_count(min_df=min_df, ngram_range=ngram_range)
# print(train_count)#(0, 8780)	1    (0, 8819)	1

count_sparse = scipy.sparse.vstack([train_count, test_count])

min_df = 3
ngram_range = (1, 5)

vect = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range, stop_words='english')

# Fit and transform
text_train = vect.fit_transform(X_train.cleaned_text)

# Convert sparse matrix to gensim corpus.
corpus = gensim.matutils.Sparse2Corpus(text_train, documents_columns=False)
# print(corpus[0])#[(10085, 0.2813134552560119), (247, 0.2540972823244096),..]

# Mapping from word IDs to words (To be used in LdaModel's id2word parameter)
id_map = dict((v, k) for k, v in vect.vocabulary_.items())
print(id_map[0])
# Use the gensim.models.ldamodel.LdaModel constructor to estimate
# LDA model parameters on the corpus, and save to the variable `ldamodel`

random_state = 324
ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=10,
                                           id2word=id_map, passes=10,
                                           random_state=random_state)


def most_probable_topic(text):
    # Transform text into Corpus
    X = vect.transform(text)
    corpus = gensim.matutils.Sparse2Corpus(X, documents_columns=False)
    # Return topic distribution
    topic_dist = ldamodel.inference(corpus)[0]
    topics = [max(enumerate(corpus), key=operator.itemgetter(1))[0] for corpus in topic_dist]
    return topics

print(most_probable_topic(X_train.cleaned_text)[0])
# One-hot encoding of topic number
train_topics = pd.get_dummies(most_probable_topic(X_train.cleaned_text), prefix='topic')
test_topics = pd.get_dummies(most_probable_topic(X_test.cleaned_text), prefix='topic')
print(train_topics.head(3))
# Amalgamating the 2 dataframes and converting them to sparse matrix
combined_topics = scipy.sparse.vstack([scipy.sparse.csr_matrix(train_topics), scipy.sparse.csr_matrix(test_topics)])

X_train.columns = [str(feat) for feat in X_train.columns.tolist()]
X_test.columns = [str(feat) for feat in X_test.columns.tolist()]
features = [feat for feat in X_train.columns.tolist()
            if feat not in ['author', 'id', 'text', 'cleaned_text']]
print(features)
df_features = pd.concat([X_train[features], X_test[features]])

# del df_features['EAP']
# del df_features['HPL']
# del df_features['MWS']

sparse_features = scipy.sparse.csr_matrix(df_features)

X = scipy.sparse.hstack([sparse_features,
                         combined_topics,
                         tfidf_sparse]).tocsr()

mapping = {'EAP': 0, 'HPL': 1, 'MWS': 2}
y_train = X_train[:nrow_train].author.map(mapping)

X_train = pd.DataFrame(X[:nrow_train].toarray())
X_test = pd.DataFrame(X[nrow_train:].toarray())


def runMNB(train_X, train_y, test_X, test_y, test_X2):
    model = naive_bayes.MultinomialNB()
    model.fit(train_X, train_y)
    pred_test_y = model.predict_proba(test_X)
    pred_test_y2 = model.predict_proba(test_X2)
    return pred_test_y, pred_test_y2, model


cv_scores = []
pred_full_test = 0
pred_train = np.zeros([nrow_train, 3])
kfolds = model_selection.KFold(n_splits=5, shuffle=True, random_state=2018)

for dev_index, val_index in kfolds.split(X_train):
    X_dev, X_val = train_count[dev_index], train_count[val_index]
    y_dev, y_val = y_train[dev_index], y_train[val_index]
    pred_y_val, pred_test_y, model = runMNB(X_dev, y_dev, X_val, y_val, test_count)
    pred_full_test = pred_full_test + pred_test_y
    pred_train[val_index, :] = pred_y_val
    cv_scores.append(metrics.log_loss(y_val, pred_y_val))

print('Mean cv score :', np.mean(cv_scores))
pred_full_test = pred_full_test / 5.

# add the predictions as new features #
print(pred_train[0:5, 0])
X_train["nb_cvec_eap"] = pred_train[:, 0]
X_train["nb_cvec_hpl"] = pred_train[:, 1]
X_train["nb_cvec_mws"] = pred_train[:, 2]
X_test["nb_cvec_eap"] = pred_full_test[:, 0]
X_test["nb_cvec_hpl"] = pred_full_test[:, 1]
X_test["nb_cvec_mws"] = pred_full_test[:, 2]

### Fit transform the tfidf vectorizer ###
tfidf_vec = CountVectorizer(ngram_range=(1, 7), analyzer='char')
tfidf_vec.fit(train['text'].values.tolist() + test['text'].values.tolist())
train_tfidf = tfidf_vec.transform(train['text'].values.tolist())
test_tfidf = tfidf_vec.transform(test['text'].values.tolist())

cv_scores = []
pred_full_test = 0
pred_train = np.zeros([nrow_train, 3])
kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2018)
for dev_index, val_index in kf.split(X_train):
    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]
    dev_y, val_y = y_train[dev_index], y_train[val_index]
    pred_val_y, pred_test_y, model = runMNB(dev_X, dev_y, val_X, val_y, test_tfidf)
    pred_full_test = pred_full_test + pred_test_y
    pred_train[val_index, :] = pred_val_y
    cv_scores.append(metrics.log_loss(val_y, pred_val_y))
print("Mean cv score : ", np.mean(cv_scores))
pred_full_test = pred_full_test / 5.

# add the predictions as new features #
X_train["nb_cvec_char_eap"] = pred_train[:, 0]
X_train["nb_cvec_char_hpl"] = pred_train[:, 1]
X_train["nb_cvec_char_mws"] = pred_train[:, 2]
X_test["nb_cvec_char_eap"] = pred_full_test[:, 0]
X_test["nb_cvec_char_hpl"] = pred_full_test[:, 1]
X_test["nb_cvec_char_mws"] = pred_full_test[:, 2]

### Fit transform the tfidf vectorizer ###
tfidf_vec = TfidfVectorizer(ngram_range=(1, 5), analyzer='char')
full_tfidf = tfidf_vec.fit_transform(train['text'].values.tolist() + test['text'].values.tolist())
train_tfidf = tfidf_vec.transform(train['text'].values.tolist())
test_tfidf = tfidf_vec.transform(test['text'].values.tolist())

cv_scores = []
pred_full_test = 0
pred_train = np.zeros([nrow_train, 3])
kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2018)
for dev_index, val_index in kf.split(X_train):
    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]
    dev_y, val_y = y_train[dev_index], y_train[val_index]
    pred_val_y, pred_test_y, model = runMNB(dev_X, dev_y, val_X, val_y, test_tfidf)
    pred_full_test = pred_full_test + pred_test_y
    pred_train[val_index, :] = pred_val_y
    cv_scores.append(metrics.log_loss(val_y, pred_val_y))
print("Mean cv score : ", np.mean(cv_scores))
pred_full_test = pred_full_test / 5.

# add the predictions as new features #
X_train["nb_tfidf_char_eap"] = pred_train[:, 0]
X_train["nb_tfidf_char_hpl"] = pred_train[:, 1]
X_train["nb_tfidf_char_mws"] = pred_train[:, 2]
X_test["nb_tfidf_char_eap"] = pred_full_test[:, 0]
X_test["nb_tfidf_char_hpl"] = pred_full_test[:, 1]
X_test["nb_tfidf_char_mws"] = pred_full_test[:, 2]


# Define a function to run Extreme Gradient Boosting
def runXGB(X_train, y_train, X_test, y_test=None, X_test2=None):
    param = {
        'objective': 'multi:softprob',
        'eta': 0.1,
        'max_depth': 3,
        'silent': 0,
        'num_class': 3,
        'eval_metric': "mlogloss",
        'min_child_weight': 3,
        'subsample': 0.8,
        'colsample_bytree': 0.7,
        'seed': 0
    }
    num_rounds = 1000
    plst = list(param.items())
    xgtrain = xgb.DMatrix(X_train, label=y_train)
    if y_test is not None:
        xgtest = xgb.DMatrix(X_test, label=y_test)
        watchlist = [(xgtrain, 'train'), (xgtest, 'test')]
        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=50, verbose_eval=20)
    else:
        xgtest = xgb.DMatrix(X_test)
        model = xgb.train(plst, xgtrain, num_rounds)
    pred_y_test = model.predict(xgtest, ntree_limit=model.best_ntree_limit)
    if X_test2 is not None:
        xgtest2 = xgb.DMatrix(X_test2)
        pred_y_test2 = model.predict(xgtest2, ntree_limit=model.best_ntree_limit)
    return pred_y_test, pred_y_test2, model


cv_scores = []
pred_full_test = 0
pred_train = np.zeros([nrow_train, 3])

for dev_index, val_index in kfolds.split(X_train):
    X_dev, X_val = X_train.loc[dev_index], X_train.loc[val_index]
    y_dev, y_val = y_train[dev_index], y_train[val_index]
    pred_y_val, pred_test_y, model = runXGB(X_dev, y_dev, X_val, y_val, X_test)
    pred_full_test = pred_full_test + pred_test_y
    pred_train[val_index, :] = pred_y_val
    cv_scores.append(metrics.log_loss(y_val, pred_y_val))

pred = pred_full_test / 5

submission = pd.read_csv('../data/sample_submission.csv')
for idx, colname in enumerate(submission.columns.tolist()):
    if colname == 'id': continue
    submission[colname] = pred[:, idx - 1]
submission.to_csv('../data/final_submission.csv', index=False)
